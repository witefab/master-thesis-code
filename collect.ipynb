{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63421dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/biographynet/dash.csv\n",
      "data/biographynet/na.csv\n",
      "data/biographynet/questionmark.csv\n",
      "data/biographynet/voor.csv\n",
      "data/biographynet/ca.csv\n",
      "data/europeana-ca/5.csv\n",
      "data/europeana-ca/2.csv\n",
      "data/europeana-ca/4.csv\n",
      "data/europeana-ca/3.csv\n",
      "data/europeana-ca/1.csv\n",
      "data/europeana-ca/6.csv\n",
      "data/europeana-?/2.csv\n",
      "data/europeana-?/3.csv\n",
      "data/europeana-?/1.csv\n",
      "29524\n",
      "52780\n",
      "82304\n",
      "15418\n",
      "sum:  97722\n"
     ]
    }
   ],
   "source": [
    "#import pandas\n",
    "#df = pandas.read_csv('data/biographynet/.csv')\n",
    "#print(df)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "path_bio = r'data/biographynet'\n",
    "path_euro_ca = r'data/europeana-ca'\n",
    "path_euro_qm = r'data/europeana-?'\n",
    "all_files = glob.glob(path_bio + \"/*.csv\")\n",
    "all_euro_ca_files = glob.glob(path_euro_ca + \"/*.csv\")\n",
    "all_euro_qm_files = glob.glob(path_euro_qm + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "li_euro_ca = []\n",
    "li_euro_qm = []\n",
    "\n",
    "for filename in all_files:\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename)\n",
    "    li.append(df)\n",
    "\n",
    "for filename in all_euro_ca_files:\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename)\n",
    "    li_euro_ca.append(df)\n",
    "    \n",
    "for filename in all_euro_qm_files:\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename)\n",
    "    li_euro_qm.append(df)\n",
    "    \n",
    "bio = pd.concat(li, axis=0, ignore_index=True)\n",
    "bio.drop(bio.columns[[0,2]], axis=1, inplace=True)\n",
    "bio_list = bio.values.tolist()\n",
    "\n",
    "euro_ca = pd.concat(li_euro_ca, axis=0, ignore_index=True)\n",
    "euro_ca.drop(euro_ca.columns[[0,1,2]], axis=1, inplace=True)\n",
    "euro_ca_list = euro_ca.values.tolist()\n",
    "\n",
    "euro_qm = pd.concat(li_euro_qm, axis=0, ignore_index=True)\n",
    "euro_qm.drop(euro_qm.columns[[0,1,2]], axis=1, inplace=True)\n",
    "euro_qm_list = euro_qm.values.tolist()\n",
    "\n",
    "euro_list = euro_ca_list + euro_qm_list\n",
    "#print(euro_ca_list)\n",
    "print(len(euro_qm_list))\n",
    "print(len(euro_ca_list))\n",
    "print(len(euro_list))\n",
    "print(len(bio_list))\n",
    "\n",
    "print(\"sum: \",len(euro_ca_list)+len(euro_qm_list)+len(bio_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5406004d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5007\n",
      "16047\n"
     ]
    }
   ],
   "source": [
    "# CASE: ca. <date>     =>    vague point in time\n",
    "HAS_CA_AND_YEAR = \".*(ca|\\d{3,4}).*(ca|\\d{3,4}).*\"\n",
    "NO_DOUBLE_CA_OR_YEAR = \"^(?!.*(ca.*?(ca)))(?!.*(\\d{4}.*?(\\d{4}))).*$\"\n",
    "MATCH_YMD_FORMAT= \".*(\\d{4}-\\d{2}-\\d{2}).*(Ca|ca).*\"\n",
    "YEAR_QM = \".*\\d{4}\\?.*\"\n",
    "\n",
    "\n",
    "def getCaYearList(date_list):\n",
    "    ca_year = []\n",
    "    no_doubles = []\n",
    "    discard = []\n",
    "    \n",
    "    for date in date_list:   \n",
    "        if re.search(HAS_CA_AND_YEAR, date[0]) and (len(date[0])<25):\n",
    "            ca_year.append(date[0])\n",
    "        else:\n",
    "            if re.search(MATCH_YMD_FORMAT, date[0]):\n",
    "                ca_year.append(date[0])\n",
    "            else:\n",
    "                discard.append(date[0])\n",
    "            \n",
    "    #print(\"discarded: \",len(discard), discard)\n",
    "    return list(filter(lambda date: re.search(NO_DOUBLE_CA_OR_YEAR, date), ca_year))\n",
    "\n",
    "#print(\"list after regex: \",len(getCaYearList(euro_ca_list)),getCaYearList(euro_ca_list))\n",
    "\n",
    "\n",
    "print(len(getCaYearList(bio_list)))\n",
    "print(len(getCaYearList(euro_list)))\n",
    "\n",
    "#print(len(bio_list))\n",
    "#print(len(getCaYearList(bio_list)))\n",
    "#print(len(euro_ca_list))\n",
    "#print(len(getCaYearList(euro_ca_list)))\n",
    "#print(bio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86749f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3609\n",
      "0\n",
      "1744\n"
     ]
    }
   ],
   "source": [
    "# CASE: TIMESPANS\n",
    "# e.g. \n",
    "# ca. <YEAR> - <YEAR>\n",
    "# <YEAR>-?-?       #precision: < 1 year\n",
    "# X-th century\n",
    "\n",
    "CA_YEAR_DASH_YEAR = \".*(Ca|ca).*\\d{4}.*-.*\\d{4}.*\" # 1955 [ca] -1960 [ca] not considered on purpose (to not include ca. 1999/ca. 1999)\n",
    "YEAR_QM_QM = \".*\\d{4}-\\?-\\?.*\"                        # only 4 matches\n",
    "CENTURY = \".*(de eeuw|century|Century|th|jahrhundert|Jahrhundert).*\"\n",
    "\n",
    "\n",
    "\n",
    "def getListWithMatchedDates(regex,dates_to_check):\n",
    "    discarded = []\n",
    "    matched = []\n",
    "    \n",
    "    for date in dates_to_check:\n",
    "        if re.search(regex, date[0]):\n",
    "            matched.append(date[0])\n",
    "        else:\n",
    "            discarded.append(date[0])\n",
    "            \n",
    "    #print(\"discarded: \", len(discarded), discarded)\n",
    "    #print(\"matched: \", len(matched), matched)\n",
    "    return matched\n",
    "\n",
    "#print(bio_list)\n",
    "#euro_year_dash_year = \n",
    "print(len(getListWithMatchedDates(CA_YEAR_DASH_YEAR, euro_list)))\n",
    "print(len(getListWithMatchedDates(YEAR_QM_QM, euro_list)))\n",
    "print(len(getListWithMatchedDates(CENTURY, euro_list)))\n",
    "#print(len(euro_year_dash_year))\n",
    "#print(euro_year_dash_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b961b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1033\n"
     ]
    }
   ],
   "source": [
    "# CASE: COMPLETE VAGUENESS\n",
    "QM = \"^[^a-z0-9]*\\?[^a-z0-9]*$\"  # just a questionmark\n",
    "\n",
    "\n",
    "print(len(getListWithMatchedDates(QM, euro_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3538bff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# CASE: BEFORE/AFTER <DATE>\n",
    "\n",
    "BEFORE_AFTER = \".*(before|after).*\\d{4}.*\"\n",
    "print(len(getListWithMatchedDates(BEFORE_AFTER, euro_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11320017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CASE: DATE OPTION\n",
    "# e.g.: 1880/1885\n",
    "# bei bio_list nur wenige matches\n",
    "\n",
    "#print(bio_list)\n",
    "YEAR_OR_YEAR = \".*\\d{4}.*\\/.*\\d{4}.*\"\n",
    "print(len(getListWithMatchedDates(YEAR_OR_YEAR, bio_list)))\n",
    "# test lololol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
